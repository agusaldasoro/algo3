\section{Metaheur\'istica GRASP}
\subsection{Explicaci\'on}

%Explicar detalladamente el algoritmo implementado. Plantear distintos criterios de parada y de seleccion de la lista de candidatos (RCL) de la heurıstica golosa aleatorizada.

La metaheur\'istica \emph{Greedy Randomized Adaptive Search Procedure} (\textbf{GRASP}), es una mezcla de las dos heur\'isticas previas (vistas en \ref{ej3} y \ref{ej4}). Dicho de manera simple: genera un punto de partida de forma golosa para el algoritmo de b\'usqueda local.\\

La distinci\'on de este algoritmo radica en cómo se construye ``\textit{golosamente}'' la soluci\'on inicial.\\

Como la sigla lo indica, consiste en un algoritmo \textit{Goloso Randomnizado}. Es decir que se escogen candidatos a soluci\'on inicial de una manera golosa ligeramente distinta a la ultilizada en la sección anterior. El método \emph{Greedy} de la sección \ref{ej3} escoge a los nodos que van a pertenecer al conjunto solución, de a uno siempre eligiendo al que tiene mayor grado. En cambio, en este caso por cada paso no se elige al nodo de mayor grado sino que se elige uno al azar entre los que ``mejor grado'' tienen.\\ 

Hablar de ``mejor grado'' nos obliga a dar un criterio  para ello, lo que da pie a la definici\'on de la \emph{Restricted Candidate List} (\textbf{RCL}), que es el conjunto de candidatos elegibles para la soluci\'on base.\\

La \emph{\textbf{solución inicial}} se puede formar de diversas maneras. En todos los casos, se añade de a un nodo al conjunto solución hasta que se forme una solución válida. Tres formas para determinar la elección por nodo son: 

\begin{itemize}

\item Elegir un nodo entre los $alpha\%$ nodos que tengan mayor grado hasta completar una soluci\'on v\'alida.

\item Elegir un nodo entre los $alpha$ nodos que tengan mayor grado hasta completar una soluci\'on v\'alida.

\item Elegir un nodo entre los nodos que cumplan determinada propiedad en un $alpha\%$ hasta completar una soluci\'on v\'alida (como por ej: ``Los nodos que tengan grado, a lo sumo, $alpha\%$ menor que el nodo de mayor grado'').

\end{itemize}

Optamos por implementar las primeras dos opciones para generar una solución inicial. Una vez obtenida la solución inicial bajo el método deseado, se aplica el algoritmo de \emph{b\'usqueda local} explicado en el inciso \ref{ej4} sin modificaciones.\\

Un aspecto tambi\'en diferencial de esta heur\'istica, es que no generamos una \'unica instancia inicial, sino que se toma una determinada cantidad de ellas (acorde al criterio de parada). Se ejecuta el algoritmo para la primer instancia y se guarda la solución como \texttt{\'optima}, luego si en alguna ejecución futura se mejora (se obtiene otra solución con menor cantidad de nodos) se actualiza \texttt{\'optima}.\\

Las \emph{\textbf{vecindades}} utilizadas son las mismas que se utilizaron en la heur\'isitca de b\'usqueda local (\ref{ej4}).\\

El \emph{\textbf{criterio de parada}} que adoptamos fue contabilizar las ejecuciones que no produjeron mejora, de modo que sólo se ejecute una determinada cantidad de repeticiones ``malas''. Es decir, siempre que la ejecución otorgue una solución óptima con menos cantidad de nodos que la existente, se seguirá ejecutando. Pero si las ejecuciones no otorgan mejoras se suman al contador, de modo que al llegar a la cantidad indicada se terminará la ejecución.

Otra opci\'on podr\'ia haber sido correr un n\'umero fijo de veces y quedarnos con la mejor soluci\'on encontrada; o tambi\'en si conocieramos alguna cota, acercarnos a esta en un determinado porcentaje; o bien una combinaci\'on de todas.

\textcolor{red}{Poner como correr 6 7 8 9 y que correnc on q parametros}

\newpage
\subsection{Experimentaci\'on}

Para analizar qu\'e combinaci\'on de vecindades de b\'usqueda local y elecci\'on de soluci\'on inicial se acercan a encontrar el \'optimo en distintos escenarios, se experiment\'o con una serie de grafos seg\'un criterios:
\begin{itemize}
	\item Mantener los ejes fijos, variando la cantidad de nodos
	\item Mantener los nodos fijos, variando la cantidad de ejes
	\item Grafos Tablero (an\'alogos a los del ``Se\~nor de los Caballos'')
\end{itemize}

\bigskip

Se opt\'o por ejecutar el algoritmo \textcolor{red}{X cantidad de veces} y luego, con los tama\~nos de cada conjunto soluci\'on, sacar un promedio.

Es decir, obtener un promedio de la cantidad de nodos que requer\'ia la soluci\'on \'optima en cada ejecuci\'on del algoritmo.\\


Luego, sabiendo cu\'antos son los nodos que pertenecen a la soluci\'on \'optima (ejecutando el algoritmo exacto), divimos y obtuvimos en qu\'e porcentaje la heur\'istica falla en encontrar el \textit{\'optimo verdadero}.\\

La siguiente tabla muestra los valores obtenidos, las columnas 2, 3 y 4 indican el criterio aplicado al grafo.\\

\textcolor{red}{Sory, la tabla no la puedo corregir, no la entiendo bien}

Vecindad 2x1 indica que la vecindad usada fue la de quitar dos nodos y agregar uno, vecindad 3x1 quitar tres y agregar uno.\\

N representa el alfa elegido.\\

N mejores indica que como criterio de b\'usqueda de soluci\'on inicial, se tom\'o uno entre los N mejores seg\'un el criterio greedy establecido, N\% mejores indica seleccionar uno entre los que pertenezcan al N\% de los mejores\\

La diferencia en las dos tablas radica en el criterio de parada, para la primera, se tom\'o la decisi\'on de no seguir buscando si no se modific\'o el \'optimo luego de 5 iteraciones, para la segunda, si no se lo modific\'o luego de 10.\\

\begin{table}[h!]
	\begin{tabular}[c]{|l|l|l|l|}
	\hline & Ejes Fijos & Nodos Fijos & Tableros \\
	\hline Vecindad 2x1 3 mejores & 0.1444444444 & 0.0443696313 & 0 \\
	\hline Vecindad 2x1 5 mejores & 0.0873015873 & 0.0878199237 & 0.7916666667 \\
	\hline Vecindad 2x1 7 mejores & 0.1272510823 & 0.0897730705 & 0.8083333333 \\
	\hline Vecindad 2x1 10 mejores & 0.0977272727 & 0.1190627034 & 0.75 \\
	\hline Vecindad 2x1 12 mejores & 0.1186147186 & 0.1041559051 & 0.4583333333 \\
	\hline Vecindad 3x1 3 mejores & 0.278466811 & 0.151036013 & 0.0833333333 \\
	\hline Vecindad 3x1 5 mejores & 0.1813888889 & 0.2439944838 & 0.5416666667 \\
	\hline Vecindad 3x1 7 mejores & 0.2068867244 & 0.2352629853 & 0.8083333333 \\
	\hline Vecindad 3x1 10 mejores & 0.2764466089 & 0.2326181999 & 0.8333333333 \\
	\hline Vecindad 3x1 12 mejores & 0.258968254 & 0.2521559379 & 0.1666666667 \\
	\hline Vecindad 2x1 10\% & 0.086468254 & 0.0821545316 & 0 \\
	\hline Vecindad 2x1 25\% & 0.1322474747 & 0.0895125969 & 0.4583333333 \\
	\hline Vecindad 2x1 50\% & 0.1164862915 & 0.0996809898 & 0.7416666667 \\
	\hline Vecindad 2x1 75\% & 0.1488816739 & 0.1212623738 & 1.075 \\
	\hline Vecindad 2x1 100\% & 0.0852272727 & 0.0990432947 & 1.0333333333 \\
	\hline Vecindad 3x1 10\% & 0.2001839827 & 0.1837163913 & 0 \\
	\hline Vecindad 3x1 25\% & 0.1706132756 & 0.1460248135 & 0.1666666667 \\
	\hline Vecindad 3x1 50\% & 0.2624531025 & 0.203697747 & 0.4833333333 \\
	\hline Vecindad 3x1 75\% & 0.2133477633 & 0.2416739045 & 0.9416666667 \\
	\hline Vecindad 3x1 100\% & 0.2849206349 & 0.2945727019 & 0.4833333333 \\
	\hline
	\end{tabular}
\caption{Promedio de porcentajes de error de GRASP con respecto al algoritmo exacto para cada vecindad y cada selecci\'on de soluci\'on inicial. Con criterio de parada fijado en 5 repeticiones sin mejorar la mejor soluci\'on hallada}
\end{table}
 
\begin{table}[h!]
	\begin{tabular}[c]{|l|l|l|l|}
	\hline & Ejes Fijos & Nodos Fijos & Tableros \\
	\hline Vecindad 2x1 3 mejores & 0.1823232323 & 0.0716093318 & 0.3333333333 \\
	\hline Vecindad 2x1 5 mejores & 0.1201370851 & 0.0936978155 & 0.4166666667 \\
	\hline Vecindad 2x1 7 mejores & 0.1566738817 & 0.0903101931 & 0.3333333333 \\
	\hline Vecindad 2x1 10 mejores & 0.1187950938 & 0.124087402 & 0.6166666667 \\
	\hline Vecindad 2x1 12 mejores & 0.0911976912 & 0.1113699446 & 0.6166666667 \\
	\hline Vecindad 3x1 3 mejores & 0.2596572872 & 0.1778930085 & 0.55 \\
	\hline Vecindad 3x1 5 mejores & 0.2637698413 & 0.2698233628 & 0.6333333333 \\
	\hline Vecindad 3x1 7 mejores & 0.3213239538 & 0.2286797787 & 0.55 \\
	\hline Vecindad 3x1 10 mejores & 0.2844047619 & 0.2735979587 & 0.4833333333 \\
	\hline Vecindad 3x1 12 mejores & 0.2242460317 & 0.269319628 & 0.2833333333 \\
	\hline Vecindad 2x1 10\% & 0.0830808081 & 0.0538074353 & 0 \\
	\hline Vecindad 2x1 25\% & 0.1161616162 & 0.0841469551 & 0 \\
	\hline Vecindad 2x1 50\% & 0.218989899 & 0.1268513858 & 0.325 \\
	\hline Vecindad 2x1 75\% & 0.2454076479 & 0.126309841 & 0.3333333333 \\
	\hline Vecindad 2x1 100\% & 0.2024242424 & 0.1329405378 & 0.8333333333 \\
	\hline Vecindad 3x1 10\% & 0.1853138528 & 0.1630435123 & 0 \\
	\hline Vecindad 3x1 25\% & 0.2839177489 & 0.2205421872 & 0.1666666667 \\
	\hline Vecindad 3x1 50\% & 0.2687914863 & 0.212152652 & 0.45 \\
	\hline Vecindad 3x1 75\% & 0.3088888889 & 0.1862762984 & 0.5916666667 \\
	\hline Vecindad 3x1 100\% & 0.3076803752 & 0.2703141941 & 0.9666666667 \\
	\hline
	\end{tabular}
\caption{Promedio de porcentajes de error de GRASP con respecto al algoritmo exacto para cada vecindad y cada selecci\'on de soluci\'on inicial. Con criterio de parada fijado en 10 repeticiones sin mejorar la mejor soluci\'on hallada}
\end{table}

\newpage

Para seleccionar la mejor combinaci\'on de par\'ametros de la heur\'istica, respecto a la soluci\'on encontrada contra la \'optima del algoritmo exacto, tomamos como criterio que se minimice la suma de cada fila, es decir, que para casos donde los grafos incrementan su cantidad de ejes, o bien solo su cantidad de nodos, y tableros de caballos, la diferencia contra la \'optima sea m\'inima.\\

Esto nos lleva a que la combinaci\'on \'optima es: Vecindad 2x1 10\% mejores con 10 iteraciones consecutivas sin ver modificaciones en el \'optimo hallado hasta ese momento. Con un error promedio del 4,5\%.


%Realizar una experimentacion que permita observar los tiempos de ejecucion y la calidad de las soluciones obtenidas. Se debe experimentar variando los valores de los parametros de la metaheurıstica (lista de candidatos, criterios de parada, etc.) y las vecindades utilizadas en la busqueda local. Elegir, si es posible, la configuracion que mejores resultados provea para el grupo de instancias utilizado.
